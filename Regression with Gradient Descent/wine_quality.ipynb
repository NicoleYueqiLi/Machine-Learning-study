{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6d08219c-7cf7-46b9-9b3a-ba395404dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc49df-8c7b-4b8c-8f51-6c7f84fdece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Class\n",
    "class Linear_Regression():\n",
    "    def __init__(self, data):\n",
    "        self.data = data # Pandas data frame\n",
    "        self.n = self.data.shape[0]\n",
    "        self.p = self.data.shape[1]-1\n",
    "        self.X = self.data.iloc[:, :self.p].to_numpy()\n",
    "        self.X = np.insert(self.X, 0, np.ones(self.n), axis=1)\n",
    "        self.Y = self.data.iloc[:, -1].to_numpy().reshape(-1, 1)\n",
    "        self.param = np.random.uniform(low=-1, high=1, size=[self.p+1, 1])\n",
    "        print(\"Params Dim: \", self.p)\n",
    "        print(\"Data Size: \", self.n)\n",
    "        \n",
    "        # Pre-Computed results\n",
    "        self.XTX = np.matmul(np.transpose(self.X), self.X)\n",
    "        self.XTY = np.matmul(np.transpose(self.X), self.Y)\n",
    "        \n",
    "    \n",
    "    def h_func(self):\n",
    "        return np.matmul(self.X, self.param)\n",
    "    \n",
    "    def MSE(self):\n",
    "        return ((self.h_func() - self.Y) ** 2).sum() / self.n\n",
    "    \n",
    "    def loss(self):\n",
    "        return self.MSE() / 2\n",
    "    \n",
    "    def grad(self):\n",
    "        return (np.matmul(self.XTX, self.param) - self.XTY) / self.n\n",
    "    \n",
    "    def evaluate(self, newdata):\n",
    "        # newdata requires to be numpy format in size of m-by-11\n",
    "        new_X = newdata.reshape(-1, self.p).copy()\n",
    "        new_X  = np.insert(new_X , 0, np.ones(new_X .shape[0]), axis=1)\n",
    "        return np.matmul(new_X, self.param)\n",
    "    def cheat(self):\n",
    "        opt_param = np.matmul(np.linalg.inv(self.XTX), self.XTY)\n",
    "        opt_MSE = ((np.matmul(self.X, opt_param) - self.Y) ** 2).sum() / self.n\n",
    "        print(\"Theoretical Optimized MSE: \", opt_MSE)\n",
    "        print(\"Theoretical Optimized Params: \", '\\n',opt_param)\n",
    "\n",
    "        \n",
    "    \n",
    "class GD():\n",
    "    def __init__(self, alpha, model):\n",
    "        self.model = model # A model class, require model has attributes named \"loss\" and \"grad\"\n",
    "        self.alpha = alpha # Learning Rate\n",
    "        \n",
    "    def step(self):\n",
    "        grad = self.model.grad()\n",
    "        self.model.param -= grad * self.alpha\n",
    "    \n",
    "    def model_reset(self):\n",
    "        self.model.param = np.random.uniform(low=-1, high=1, size=[self.model.p+1, 1])\n",
    "    \n",
    "    def train(self, max_iter, log_interval = 1):\n",
    "        for i in range(max_iter):\n",
    "            self.step()\n",
    "            if i % log_interval == 0:\n",
    "                print(\"Iteration: \", i, \"Loss: \", self.model.loss())\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c2ad3955-d1af-496e-a17d-b434bcc93279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv(\"winequality-red.csv\")\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "898d0d89-93bb-4da7-b670-49f001c34692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Dim:  11\n",
      "Data Size:  1599\n",
      "Iteration:  0 Loss:  569.632708345379\n",
      "Iteration:  1000000 Loss:  0.23797679757334844\n",
      "Iteration:  2000000 Loss:  0.23075987671370193\n",
      "Iteration:  3000000 Loss:  0.22630731875015456\n",
      "Iteration:  4000000 Loss:  0.22338985794194444\n",
      "Iteration:  5000000 Loss:  0.22136789889602762\n",
      "Iteration:  6000000 Loss:  0.2198953130833707\n",
      "Iteration:  7000000 Loss:  0.21877775979612774\n",
      "Iteration:  8000000 Loss:  0.21790139863228047\n",
      "Iteration:  9000000 Loss:  0.21719630782179883\n",
      "Parameters:  \n",
      " [[-9.32631714e-02]\n",
      " [ 4.63891272e-02]\n",
      " [-9.21517069e-01]\n",
      " [ 3.42736529e-02]\n",
      " [-4.29593279e-04]\n",
      " [ 5.19908644e-01]\n",
      " [ 4.67079740e-03]\n",
      " [-2.76123961e-03]\n",
      " [ 1.21035357e+00]\n",
      " [ 2.41734938e-01]\n",
      " [ 6.77708553e-01]\n",
      " [ 3.23866568e-01]]\n",
      "MSE:  0.4332347448601869\n",
      "Theoretical Optimized MSE:  0.41676716722140816\n",
      "Theoretical Optimized Params:  \n",
      " [[ 2.19652085e+01]\n",
      " [ 2.49905527e-02]\n",
      " [-1.08359026e+00]\n",
      " [-1.82563948e-01]\n",
      " [ 1.63312698e-02]\n",
      " [-1.87422516e+00]\n",
      " [ 4.36133331e-03]\n",
      " [-3.26457970e-03]\n",
      " [-1.78811639e+01]\n",
      " [-4.13653144e-01]\n",
      " [ 9.16334413e-01]\n",
      " [ 2.76197699e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "dat = pd.read_csv(\"winequality-red.csv\")\n",
    "lm = Linear_Regression(dat)\n",
    "optimizer = SGD(1e-5, lm)\n",
    "# Train\n",
    "optimizer.model_reset()\n",
    "optimizer.train(10000000, log_interval = 1000000)\n",
    "print(\"Parameters: \",'\\n', optimizer.model.param)\n",
    "print(\"MSE: \", optimizer.model.MSE())\n",
    "optimizer.model.cheat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "903ff596-e8ad-4eb7-a668-fbbd2fc61002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13764471  0.23640751  0.2775234  ... -0.11981331  0.39685045\n",
      " -0.39787425]\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "pred = optimizer.model.evaluate(dat.iloc[:, :-1].to_numpy()).reshape(-1)\n",
    "label = dat.iloc[:, -1].to_numpy()\n",
    "print(pred - label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269806c-941a-4eeb-8b95-286f2244990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------Bouns---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "553ef0c5-1b18-4667-8bf9-d9a8a0bb8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Class\n",
    "class Ridge_Regression():\n",
    "    def __init__(self, data,lamda=0.05):\n",
    "        self.data = data # Pandas data frame\n",
    "        self.n = self.data.shape[0]\n",
    "        self.lamda =lamda\n",
    "        self.p = self.data.shape[1]-1\n",
    "        self.X = self.data.iloc[:, :self.p].to_numpy()\n",
    "        self.X = np.insert(self.X, 0, np.ones(self.n), axis=1)\n",
    "        self.Y = self.data.iloc[:, -1].to_numpy().reshape(-1, 1)\n",
    "        self.param = np.random.uniform(low=-1, high=1, size=[self.p+1, 1])\n",
    "        print(\"Params Dim: \", self.p)\n",
    "        print(\"Data Size: \", self.n)\n",
    "        \n",
    "        # Pre-Computed results\n",
    "        self.XTX = np.matmul(np.transpose(self.X), self.X)\n",
    "        self.XTY = np.matmul(np.transpose(self.X), self.Y)\n",
    "        \n",
    "    \n",
    "    def h_func(self):\n",
    "        return np.matmul(self.X, self.param)\n",
    "    \n",
    "    def MSE(self):\n",
    "        return ((self.h_func() - self.Y) ** 2).sum() / self.n\n",
    "    \n",
    "    def loss(self):\n",
    "        return self.MSE() / 2 + self.lamda / 2 * np.linalg.norm(self.param, ord=2) ** 2\n",
    "    \n",
    "    def grad(self):\n",
    "        return (np.matmul(self.XTX, self.param) - self.XTY) / self.n + self.lamda*self.param\n",
    "    \n",
    "    def evaluate(self, newdata):\n",
    "        # newdata requires to be numpy format in size of m-by-11\n",
    "        new_X = newdata.reshape(-1, self.p).copy()\n",
    "        new_X  = np.insert(new_X , 0, np.ones(new_X .shape[0]), axis=1)\n",
    "        return np.matmul(new_X, self.param)\n",
    "    \n",
    "    def cheat(self):\n",
    "        opt_param = np.matmul(np.linalg.inv(self.XTX + self.n * self.lamda * np.identity(self.p+1)), self.XTY)\n",
    "        opt_MSE = ((np.matmul(self.X, opt_param) - self.Y) ** 2).sum() / self.n\n",
    "        print(\"Theoretical Optimized MSE: \", opt_MSE)\n",
    "        print(\"Theoretical Optimized Params: \", '\\n',opt_param)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "class SGD():\n",
    "    def __init__(self, alpha, model):\n",
    "        self.model = model # A model class, require model has attributes named \"loss\" and \"grad\"\n",
    "        self.alpha = alpha # Learning Rate\n",
    "        \n",
    "    def step(self):\n",
    "        grad = self.model.grad()\n",
    "        self.model.param -= grad * self.alpha\n",
    "    \n",
    "    def model_reset(self):\n",
    "        self.model.param = np.random.uniform(low=-1, high=1, size=[self.model.p+1, 1])\n",
    "    \n",
    "    def train(self, max_iter, log_interval = 1):\n",
    "        for i in range(max_iter):\n",
    "            self.step()\n",
    "            if i % log_interval == 0:\n",
    "                print(\"Iteration: \", i, \"Loss: \", self.model.loss())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cf40991a-c4cd-489d-87df-e6c0ba06e781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params Dim:  11\n",
      "Data Size:  1599\n",
      "Iteration:  0 Loss:  1898.9463224292754\n",
      "Iteration:  100000 Loss:  0.3514074787756891\n",
      "Iteration:  200000 Loss:  0.31066671155820125\n",
      "Iteration:  300000 Loss:  0.3004928267405232\n",
      "Iteration:  400000 Loss:  0.29248747892279864\n",
      "Iteration:  500000 Loss:  0.28570659730451925\n",
      "Iteration:  600000 Loss:  0.2799092524310344\n",
      "Iteration:  700000 Loss:  0.27492118282495415\n",
      "Iteration:  800000 Loss:  0.27060635392339377\n",
      "Iteration:  900000 Loss:  0.2668570009225045\n",
      "Parameters:  \n",
      " [[-0.19574729]\n",
      " [ 0.06195677]\n",
      " [ 0.22061364]\n",
      " [ 0.63702315]\n",
      " [-0.01061737]\n",
      " [-0.15446372]\n",
      " [ 0.00870548]\n",
      " [-0.00347562]\n",
      " [ 0.00635119]\n",
      " [ 0.36865838]\n",
      " [ 0.19469945]\n",
      " [ 0.35795426]]\n",
      "MSE:  0.486039782944652\n",
      "Theoretical Optimized MSE:  0.4545180872783981\n",
      "Theoretical Optimized Params:  \n",
      " [[ 0.11890313]\n",
      " [ 0.08292512]\n",
      " [-0.35321197]\n",
      " [ 0.06124528]\n",
      " [-0.00408968]\n",
      " [-0.02174472]\n",
      " [ 0.00663976]\n",
      " [-0.00255687]\n",
      " [ 0.11737472]\n",
      " [ 0.24945799]\n",
      " [ 0.32387003]\n",
      " [ 0.37039913]]\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "dat = pd.read_csv(\"winequality-red.csv\")\n",
    "lm = Ridge_Regression(dat,lamda=0.05)\n",
    "optimizer = SGD(1e-5, lm)\n",
    "# Train\n",
    "optimizer.model_reset()\n",
    "optimizer.train(1000000, log_interval = 100000)\n",
    "print(\"Parameters: \",'\\n', optimizer.model.param)\n",
    "print(\"MSE: \", optimizer.model.MSE())\n",
    "optimizer.model.cheat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50889eba-940a-4007-b71c-32c5b165435b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
