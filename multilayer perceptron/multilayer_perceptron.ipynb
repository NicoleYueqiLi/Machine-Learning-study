{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cbd29fc-bad4-4d64-be44-53d770ca1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import sympy\n",
    "from sympy.abc import x\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0974358f-284e-4c3d-a0be-bda30a03bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.type = \"linear\"\n",
    "        self.input_dim = input_dim # 2-dim Matrix, each row defines each piece of data\n",
    "        self.output_dim = output_dim # Int, output dimensionality\n",
    "        \n",
    "        # Weight Matrix: Right Multiplication, Glorot Initialization\n",
    "        self.W = np.random.uniform(low=-1, high=1, size=(self.input_dim, self.output_dim)) / np.sqrt(6 / (self.input_dim + self.output_dim))\n",
    "        self.b = np.random.uniform(low=-1, high=1, size=(self.output_dim, )) / np.sqrt(6 / self.output_dim)\n",
    "        self.W_grad = None\n",
    "        self.b_grad = None\n",
    "        \n",
    "    def forward(self, Input):\n",
    "        self.W_grad = np.transpose(Input)\n",
    "        return np.matmul(Input, self.W) + self.b\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        self.W_grad = np.matmul(self.W_grad, output_grad)\n",
    "        self.b_grad = output_grad.sum(0)\n",
    "        return np.matmul(output_grad, np.transpose(self.W))\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.type = \"act_fun\"\n",
    "        self.output = None\n",
    "        \n",
    "    def forward(self, Input):\n",
    "        self.output = 1 / (1 + np.exp(-Input))\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        return self.output * (1 - self.output) * output_grad\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.type = \"act_fun\"\n",
    "        self.output = None\n",
    "        \n",
    "    def forward(self, Input):\n",
    "        Exp = np.exp(Input)\n",
    "        total = Exp.sum(1, keepdims=True)\n",
    "        self.output = Exp / total\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        product = self.output * output_grad\n",
    "        return self.output * (output_grad - product.sum(1, keepdims=True))\n",
    "\n",
    "class MeanCategoricalCrossEntropy:\n",
    "    def __init__(self, label_idx):\n",
    "        self.label_idx = label_idx\n",
    "        \n",
    "    def forward(self, Input):\n",
    "        self.input = Input\n",
    "        return - np.sum(self.label_idx * np.log(Input)) / self.label_idx.shape[0]\n",
    "    \n",
    "    def backward(self):\n",
    "        return - (self.label_idx / self.input) / self.label_idx.shape[0]\n",
    "\n",
    "class Flow:\n",
    "    def __init__(self, flow=[]):\n",
    "        self.flow = flow\n",
    "#         self.loss = loss\n",
    "        \n",
    "    def forward(self, data):\n",
    "        if not self.flow:\n",
    "            print(\"Error: Empty Neural Network\")\n",
    "            return\n",
    "        \n",
    "        x = data.copy()\n",
    "        for layer in self.flow:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, loss_grad):\n",
    "        if not self.flow:\n",
    "            print(\"Error: Empty Neural Network\")\n",
    "            return\n",
    "        \n",
    "        y = loss_grad.copy()\n",
    "        for layer in self.flow[::-1]:\n",
    "            y = layer.backward(y)\n",
    "        return y\n",
    "    \n",
    "class SGD:\n",
    "    def __init__(self, model, lr):\n",
    "        self.lr = lr\n",
    "        self.model = model\n",
    "    \n",
    "    def step(self):\n",
    "        for layer in self.model.flow:\n",
    "            if layer.type == \"linear\":\n",
    "                layer.W -= layer.W_grad * self.lr\n",
    "                layer.b -= layer.b_grad * self.lr\n",
    "                layer.W_grad = None\n",
    "                layer.b_grad = None \n",
    "\n",
    "class Dataloader:\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.batch_size = len(self.data) // 10 + 1\n",
    "        self.shuffle = True\n",
    "        self.index = np.array([i for i in range(data.shape[0])])\n",
    "        self.data_batches = []\n",
    "        self.label_batches = []\n",
    "        self.build()\n",
    "        \n",
    "    \n",
    "    def build(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.index)\n",
    "        \n",
    "        index_batches = np.split(self.index, np.arange(self.batch_size, self.index.shape[0], self.batch_size))\n",
    "        self.data_batches.clear()\n",
    "        self.label_batches.clear()\n",
    "        for ind in index_batches:\n",
    "            self.data_batches.append(self.data[self.index[ind], :])\n",
    "            self.label_batches.append(self.label[self.index[ind], :])\n",
    "#         curr_idx = 0\n",
    "#         while True:\n",
    "#             if curr_idx + self.batch_size <= self.index.shape[0]:\n",
    "#                 self.data_batches.append(self.data[self.index[curr_idx:curr_idx + self.batch_size], :])\n",
    "#                 self.label_batches.append(self.label[self.index[curr_idx:curr_idx + self.batch_size], :])\n",
    "#                 curr_idx += self.batch_size\n",
    "#             else:\n",
    "#                 self.data_batches.append(self.data[self.index[curr_idx:], :])\n",
    "#                 self.label_batches.append(self.label[self.index[curr_idx:], :])\n",
    "#                 break\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6eec08bb-adae-4dc2-8a15-ac7656ffb81b",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "---------------------------------MNIST_0_1 ------------------------------------\n",
    "\n",
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf8dd53-0cef-4d4e-8e61-22aa292110c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 :  1.3479192261358648\n",
      "Epoch  5 :  0.08704795738613064\n",
      "Epoch  10 :  0.056251928151025095\n",
      "Epoch  15 :  0.042164014444657186\n",
      "Epoch  20 :  0.03743504417390316\n",
      "Epoch  25 :  0.03101420848033281\n",
      "Epoch  30 :  0.029982307395125564\n",
      "Epoch  35 :  0.02574813999041033\n",
      "Epoch  40 :  0.025002378864070144\n",
      "Epoch  45 :  0.022719901677019504\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"mnist_train_0_1.csv\",header=None)\n",
    "data = data1.iloc[:,1:].to_numpy() / 255\n",
    "label1 = data1.iloc[:,0]\n",
    "label = pd.get_dummies(label1).to_numpy()\n",
    "\n",
    "dataloader = Dataloader(data, label)\n",
    "dataloader.batch_size = 500\n",
    "\n",
    "net = Flow()\n",
    "net.flow = [Linear(784,64), Sigmoid(), Linear(64,2), Softmax()]\n",
    "loss = MeanCategoricalCrossEntropy(label)\n",
    "optimizer = SGD(net, 0.5)\n",
    "for epoch in range(50):\n",
    "    loss_record = []\n",
    "    dataloader.build()\n",
    "    for batch_data, batch_label in zip(dataloader.data_batches, dataloader.label_batches):\n",
    "        loss.label_idx = batch_label\n",
    "        y_hat = optimizer.model.forward(batch_data)\n",
    "        loss_record.append(loss.forward(y_hat))\n",
    "        optimizer.model.backward(loss.backward())\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch \", epoch, \": \", np.array(loss_record).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa2e7565-e05f-47f7-80e9-1af504a18885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonus Training Confusion: \n",
      " [[5888   35]\n",
      " [  36 6706]]\n",
      "Training Accuracy:  0.9943939992104224\n",
      "\n",
      " Bonus Testing Confusion: \n",
      " [[ 974    6    0    0    0]\n",
      " [   7 1128    0    0    0]\n",
      " [   0    0    0    0    0]\n",
      " [   0    0    0    0    0]\n",
      " [   0    0    0    0    0]]\n",
      "Testing Accuracy:  0.9938534278959811\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(optimizer.model.forward(data), axis=1)\n",
    "num_classes = 2\n",
    "confmat = np.array([[0]*num_classes for _ in range(num_classes)])\n",
    "for pred, label in zip(preds, np.array(label1)):\n",
    "    confmat[label][pred] += 1\n",
    "print(\"Bonus Training Confusion: \\n\", confmat)\n",
    "print(\"Training Accuracy: \", confmat.diagonal().sum() / confmat.sum())  \n",
    "\n",
    "test = pd.read_csv(\"mnist_test_0_1.csv\",header=None)\n",
    "t_data = test.iloc[:,1:].to_numpy() / 255\n",
    "t_label = test.iloc[:,0].to_numpy()\n",
    "\n",
    "preds = np.argmax(optimizer.model.forward(t_data), axis=1)\n",
    "num_classes = 5\n",
    "confmat = np.array([[0]*num_classes for _ in range(num_classes)])\n",
    "for pred, label in zip(preds, np.array(t_label)):\n",
    "    confmat[label][pred] += 1\n",
    "print(\"\\n Bonus Testing Confusion: \\n\", confmat)\n",
    "print(\"Testing Accuracy: \", confmat.diagonal().sum() / confmat.sum())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1025f4-2164-4b46-8709-5ed1c06e0f5a",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "----------------------------MNIST_0_4 Bonus------------------------------------\n",
    "\n",
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ba87256-0697-458b-8f14-fa08f75573b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 :  5.888010814782005\n",
      "Epoch  5 :  0.3036209249977863\n",
      "Epoch  10 :  0.20509253794094862\n",
      "Epoch  15 :  0.16969604610403233\n",
      "Epoch  20 :  0.1446702458312133\n",
      "Epoch  25 :  0.12791691445252112\n",
      "Epoch  30 :  0.11286100122018082\n",
      "Epoch  35 :  0.10231389669167983\n",
      "Epoch  40 :  0.09197075003280927\n",
      "Epoch  45 :  0.08630229396757967\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"mnist_train_0_4.csv\",header=None)\n",
    "data = data1.iloc[:,1:].to_numpy() / 255\n",
    "label1 = data1.iloc[:,0]\n",
    "label = pd.get_dummies(label1).to_numpy()\n",
    "\n",
    "dataloader = Dataloader(data, label)\n",
    "dataloader.batch_size = 500\n",
    "\n",
    "net = Flow()\n",
    "net.flow = [Linear(784,128), Sigmoid(), Linear(128,64), Sigmoid(), Linear(64,5), Softmax()]\n",
    "loss = MeanCategoricalCrossEntropy(label)\n",
    "optimizer = SGD(net, 5.0)\n",
    "for epoch in range(50):\n",
    "    loss_record = []\n",
    "    dataloader.build()\n",
    "    for batch_data, batch_label in zip(dataloader.data_batches, dataloader.label_batches):\n",
    "        loss.label_idx = batch_label\n",
    "        y_hat = optimizer.model.forward(batch_data)\n",
    "        loss_record.append(loss.forward(y_hat))\n",
    "        optimizer.model.backward(loss.backward())\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch \", epoch, \": \", np.array(loss_record).mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6400fca1-9c7f-48c2-9a13-893b0230eddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonus Training Confusion: \n",
      " [[5822    0   56   32   13]\n",
      " [   0 6681   34   19    8]\n",
      " [  43   21 5782   85   27]\n",
      " [  31   10  182 5883   25]\n",
      " [  14   21   67   28 5712]]\n",
      "Training Accuracy:  0.9765982481370113\n",
      "\n",
      " Bonus Testing Confusion: \n",
      " [[ 939    3   23   11    4]\n",
      " [   0 1112   12    8    3]\n",
      " [  22   14  942   40   14]\n",
      " [  14   15   42  928   11]\n",
      " [   9   12   35   19  907]]\n",
      "Testing Accuracy:  0.9394823895699552\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(optimizer.model.forward(data), axis=1)\n",
    "num_classes = 5\n",
    "confmat = np.array([[0]*num_classes for _ in range(num_classes)])\n",
    "for pred, label in zip(preds, np.array(label1)):\n",
    "    confmat[label][pred] += 1\n",
    "print(\"Bonus Training Confusion: \\n\", confmat)\n",
    "print(\"Training Accuracy: \", confmat.diagonal().sum() / confmat.sum())  \n",
    "\n",
    "test = pd.read_csv(\"mnist_test_0_4.csv\",header=None)\n",
    "t_data = test.iloc[:,1:].to_numpy() / 255\n",
    "t_label = test.iloc[:,0].to_numpy()\n",
    "\n",
    "preds = np.argmax(optimizer.model.forward(t_data), axis=1)\n",
    "num_classes = 5\n",
    "confmat = np.array([[0]*num_classes for _ in range(num_classes)])\n",
    "for pred, label in zip(preds, np.array(t_label)):\n",
    "    confmat[label][pred] += 1\n",
    "print(\"\\n Bonus Testing Confusion: \\n\", confmat)\n",
    "print(\"Testing Accuracy: \", confmat.diagonal().sum() / confmat.sum())  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
